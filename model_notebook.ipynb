{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['category']\n",
    "X = data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162980,)\n",
      "(162980,)\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(type(X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapNanValues(data):\n",
    "    nan_values = []\n",
    "    for i in range(len(data)):\n",
    "        if type(data[i]) == float:\n",
    "            nan_values.append(i)\n",
    "    return nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148, 158694, 159443, 160560]\n",
      "(162976,)\n",
      "(162976,)\n"
     ]
    }
   ],
   "source": [
    "values = mapNanValues(X)\n",
    "print(values)\n",
    "y = y.drop(index=values).reset_index(drop=True)\n",
    "X = X.drop(index=values).reset_index(drop=True)\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "zeros = np.zeros((len(y), 3))\n",
    "##### One Hot labels ####\n",
    "for i in range(len(y)):\n",
    "    if y[i] == -1:\n",
    "        zeros[i][0] = 1\n",
    "    elif y[i] == 0:\n",
    "        zeros[i][1] = 1\n",
    "    elif y[i] == 1:\n",
    "        zeros[i][2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Softmax, Dropout, Input, Embedding, TextVectorization\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras import Model\n",
    "#from tensorflow.keras.preprocessing.text import one_hot\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bert_LSTM():\n",
    "    text_input = Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessed_text = bert_preprocess(text_input)\n",
    "    outputs = bert_encoder(preprocessed_text)\n",
    "    l = Dropout(0.1)(outputs['pooled_output'])\n",
    "    l = Dense(128, activation='relu')(l)\n",
    "    l = Dropout(0.1)(l)\n",
    "    l = Dense(32)(l)\n",
    "    output = Dense(3, activation='softmax')(l)\n",
    "    model = Model(inputs=[text_input], outputs = [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trainable_Embedding_LSTM(data):\n",
    "    intencoding = TextVectorization(max_tokens=999, output_mode='int', output_sequence_length=40)\n",
    "    intencoding.adapt(data)\n",
    "    intencoding.compile()\n",
    "    text_input = Input(shape=(), dtype=tf.string, name='text')\n",
    "    textvec = intencoding(text_input)\n",
    "    l = Embedding(input_dim=999, output_dim=100)(textvec)\n",
    "    l = LSTM(128, input_shape=(40, 100), activation='relu', return_sequences=True)(l)\n",
    "    l = Dropout(0.1)(l)\n",
    "    l = LSTM(128, activation='relu', return_sequences=False)(l)\n",
    "    l = Dropout(0.1)(l)\n",
    "    l = Dense(32)(l)\n",
    "    output = Dense(3, activation='softmax')(l)\n",
    "    model = Model(inputs=[text_input], outputs = [output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn import model_selection\n",
    " X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      CategoricalAccuracy(name='accuracy'),\n",
    "      Precision(name='precision'),\n",
    "      Recall(name='recall')\n",
    "]\n",
    "\n",
    "model2 = Bert_LSTM()\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "history_bert = model2.fit(X_train, y_train, batch_size = 1024, epochs=50, verbose=1)\n",
    "model2.save('bert_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_bert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(history_bert\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(history_bert\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mmodel accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_bert' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history_bert.history['accuracy'])\n",
    "plt.plot(history_bert.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Bert_Plot.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Trainable_Embedding_LSTM(X)\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', validation_split=0.2, metrics=METRICS, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "history_custom = model3.fit(X_train, y_train, batch_size = 1024, epochs=50, verbose=1)\n",
    "model3.save('custom_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_custom.history['accuracy'])\n",
    "plt.plot(history_custom.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Bert_Plot.png', format='png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2170a1b4cba516552f4fa9a78303da4aef62ca80b5cfe389d3bd0d9a3f2bfa1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
